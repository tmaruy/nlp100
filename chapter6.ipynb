{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36464bitbaseconda1d0c2e3be8214c02b0fb731b7870def2",
   "display_name": "Python 3.6.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 言語処理100本ノック 2020 第６章\n",
    "\n",
    "Reference: https://nlp100.github.io/ja/ch06.html"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir NewsAggregatorDataset\n",
    "!cd NewsAggregatorDataset\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
    "!unzip NewsAggregatorDataset.zip\n",
    "!cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifile = \"NewsAggregatorDataset/newsCorpora.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50. データの入手・整形\n",
    "\n",
    "News Aggregator Data Setをダウンロードし、以下の要領で学習データ（train.txt），検証データ（valid.txt），評価データ（test.txt）を作成せよ．\n",
    "\n",
    "* ダウンロードしたzipファイルを解凍し，readme.txtの説明を読む．\n",
    "* 情報源（publisher）が”Reuters”, “Huffington Post”, “Businessweek”, “Contactmusic.com”, “Daily Mail”の事例（記事）のみを抽出する．\n",
    "* 抽出された事例をランダムに並び替える．\n",
    "* 抽出された事例の80%を学習データ，残りの10%ずつを検証データと評価データに分割し，それぞれtrain.txt，valid.txt，test.txtというファイル名で保存する．ファイルには，１行に１事例を書き出すこととし，カテゴリ名と記事見出しのタブ区切り形式とせよ（このファイルは後に問題70で再利用する）．\n",
    "\n",
    "学習データと評価データを作成したら，各カテゴリの事例数を確認せよ．"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   ID                                              TITLE  \\\n0   1  Fed official says weak data caused by weather,...   \n1   2  Fed's Charles Plosser sees high bar for change...   \n2   3  US open: Stocks fall after Fed official hints ...   \n3   4  Fed risks falling 'behind the curve', Charles ...   \n4   5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n\n                                                 URL          PUBLISHER  \\\n0  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n1  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n2  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n3  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n4  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n\n  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \n0        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>TITLE</th>\n      <th>URL</th>\n      <th>PUBLISHER</th>\n      <th>CATEGORY</th>\n      <th>STORY</th>\n      <th>HOSTNAME</th>\n      <th>TIMESTAMP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Fed official says weak data caused by weather,...</td>\n      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n      <td>Los Angeles Times</td>\n      <td>b</td>\n      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n      <td>www.latimes.com</td>\n      <td>1394470370698</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Fed's Charles Plosser sees high bar for change...</td>\n      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n      <td>Livemint</td>\n      <td>b</td>\n      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n      <td>www.livemint.com</td>\n      <td>1394470371207</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>US open: Stocks fall after Fed official hints ...</td>\n      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n      <td>IFA Magazine</td>\n      <td>b</td>\n      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n      <td>www.ifamagazine.com</td>\n      <td>1394470371550</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Fed risks falling 'behind the curve', Charles ...</td>\n      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n      <td>IFA Magazine</td>\n      <td>b</td>\n      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n      <td>www.ifamagazine.com</td>\n      <td>1394470371793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n      <td>Moneynews</td>\n      <td>b</td>\n      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n      <td>www.moneynews.com</td>\n      <td>1394470372027</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "dat = pd.read_csv(ifile, sep=\"\\t\", header=None)\n",
    "dat.columns = [\"ID\", \"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"]\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(422419, 8)\n(13340, 8)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Reuters             3902\nHuffington Post     2455\nBusinessweek        2395\nContactmusic.com    2334\nDaily Mail          2254\nName: PUBLISHER, dtype: int64"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "print(dat.shape)\n",
    "publishers = [\"Reuters\", \"Huffington Post\", \"Businessweek\", \"Contactmusic.com\", \"Daily Mail\"]\n",
    "dat = dat.loc[dat.PUBLISHER.isin(publishers), :]\n",
    "print(dat.shape)\n",
    "dat.PUBLISHER.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((10672, 2), (1334, 2), (1334, 2))"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tmp = dat.loc[:,[\"TITLE\", \"CATEGORY\"]]\n",
    "tmp = shuffle(tmp)\n",
    "train, tmp = train_test_split(tmp, test_size=0.2)\n",
    "test, valid = train_test_split(tmp, test_size=0.5)\n",
    "\n",
    "train.shape, test.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"NewsAggregatorDataset/train.txt\", sep=\"\\t\", index=False)\n",
    "test.to_csv(\"NewsAggregatorDataset/test.txt\", sep=\"\\t\", index=False)\n",
    "valid.to_csv(\"NewsAggregatorDataset/valid.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 51. 特徴量抽出\n",
    "\n",
    "学習データ，検証データ，評価データから特徴量を抽出し，それぞれtrain.feature.txt，valid.feature.txt，test.feature.txtというファイル名で保存せよ． なお，カテゴリ分類に有用そうな特徴量は各自で自由に設計せよ．記事の見出しを単語列に変換したものが最低限のベースラインとなるであろう．"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dictionary(19395 unique tokens: ['In', 'Labeouf', 'Rehab', 'Report', 'Shia']...)\nDictionary(1894 unique tokens: ['In', 'Report', 'Shia', \"'s\", '1-China']...)\n"
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokens = [word_tokenize(text) for text in train.TITLE]\n",
    "\n",
    "# Remove (i) numbers, (ii) single-character words\n",
    "tokens = [[t for t in token if (not t.isnumeric()) and (len(t) > 1)] for token in tokens]\n",
    "\n",
    "# Create dictionary\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "print(dictionary)\n",
    "\n",
    "# Filter out words that occur less than 10 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(texts, dictionary):\n",
    "    # Tokenize\n",
    "    tokens = [word_tokenize(text) for text in texts]\n",
    "    # Vectorize\n",
    "    corpus = [dictionary.doc2bow(t) for t in tokens]\n",
    "    # \n",
    "    mat = pd.DataFrame(np.zeros([len(tokens), len(dictionary)]), \n",
    "                       columns=dictionary.token2id.keys())\n",
    "    for i,c_s in enumerate(corpus):\n",
    "        idx = [c[0] for c in c_s]\n",
    "        mat.iloc[i, idx] = 1\n",
    "    return(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    In  Report  Shia   's  1-China\n0  1.0     1.0   1.0  0.0      0.0\n1  0.0     0.0   0.0  1.0      1.0\n2  1.0     0.0   0.0  0.0      0.0\n3  0.0     0.0   0.0  1.0      0.0\n4  0.0     0.0   0.0  0.0      0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>In</th>\n      <th>Report</th>\n      <th>Shia</th>\n      <th>'s</th>\n      <th>1-China</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "x_train = vectorize(train.TITLE, dictionary)\n",
    "x_test = vectorize(test.TITLE, dictionary)\n",
    "x_valid = vectorize(valid.TITLE, dictionary)\n",
    "x_train.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 52. 学習\n",
    "\n",
    "51で構築した学習データを用いて，ロジスティック回帰モデルを学習せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "b    4544\ne    4160\nt    1240\nm     728\nName: CATEGORY, dtype: int64"
     },
     "metadata": {},
     "execution_count": 186
    }
   ],
   "source": [
    "# b = business, t = science and technology, e = entertainment, m = health\n",
    "train.CATEGORY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "341749     True\n226448    False\n19723      True\n134564     True\n41167     False\nName: CATEGORY, dtype: bool"
     },
     "metadata": {},
     "execution_count": 188
    }
   ],
   "source": [
    "# ここではエンタメ関連の記事をタイトルから予測することを目指す\n",
    "y_train = (train.CATEGORY == \"e\")\n",
    "y_test = (test.CATEGORY == \"e\")\n",
    "y_valid = (valid.CATEGORY == \"e\")\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='warn',\n          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 193
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 53. 予測\n",
    "\n",
    "52で学習したロジスティック回帰モデルを用い，与えられた記事見出しからカテゴリとその予測確率を計算するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ True, False,  True, ...,  True, False, False])"
     },
     "metadata": {},
     "execution_count": 210
    }
   ],
   "source": [
    "# 学習データ\n",
    "yt_train = lr.predict(x_train)\n",
    "yt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([False,  True,  True, ...,  True, False, False])"
     },
     "metadata": {},
     "execution_count": 212
    }
   ],
   "source": [
    "# 評価データ\n",
    "yt_test = lr.predict(x_test)\n",
    "yt_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 54. 正解率の計測\n",
    "\n",
    "52で学習したロジスティック回帰モデルの正解率を，学習データおよび評価データ上で計測せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "96.56109445277362"
     },
     "metadata": {},
     "execution_count": 222
    }
   ],
   "source": [
    "# 学習データ\n",
    "np.sum(y_train == yt_train) / len(y_train) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "91.1544227886057"
     },
     "metadata": {},
     "execution_count": 223
    }
   ],
   "source": [
    "# 評価データ\n",
    "np.sum(y_test == yt_test) / len(y_test) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 55. 混同行列の作成\n",
    "\n",
    "52で学習したロジスティック回帰モデルの混同行列（confusion matrix）を，学習データおよび評価データ上で作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Measured  False  True \nPredict               \nFalse      6368    223\nTrue        144   3937",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Measured</th>\n      <th>False</th>\n      <th>True</th>\n    </tr>\n    <tr>\n      <th>Predict</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>False</th>\n      <td>6368</td>\n      <td>223</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>144</td>\n      <td>3937</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 211
    }
   ],
   "source": [
    "# 学習データ\n",
    "perform_train = pd.DataFrame({\"Measured\":y_train, \"Predict\":yt_train}).groupby(\"Predict\").Measured.value_counts().unstack(level=1)\n",
    "perform_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Measured  False  True \nPredict               \nFalse       697     78\nTrue         40    519",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Measured</th>\n      <th>False</th>\n      <th>True</th>\n    </tr>\n    <tr>\n      <th>Predict</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>False</th>\n      <td>697</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>True</th>\n      <td>40</td>\n      <td>519</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 213
    }
   ],
   "source": [
    "# 評価データ\n",
    "perform_test = pd.DataFrame({\"Measured\":y_test, \"Predict\":yt_test}).groupby(\"Predict\").Measured.value_counts().unstack(level=1)\n",
    "perform_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 56. 適合率，再現率，F1スコアの計測\n",
    "\n",
    "52で学習したロジスティック回帰モデルの適合率(precision)，再現率(recall)，F1スコアを，評価データ上で計測せよ．カテゴリごとに適合率，再現率，F1スコアを求め，カテゴリごとの性能をマイクロ平均（micro-average）とマクロ平均（macro-average）で統合せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(mat):\n",
    "    precision = mat.loc[True,True] / np.sum(mat.loc[True,:])\n",
    "    recall = mat.loc[True,True] / np.sum(mat.loc[:,True])\n",
    "    f1score = (2 * precision * recall) / (precision + recall)\n",
    "    return precision, recall, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.9647145307522667, 0.9463942307692308, 0.9554665695910691)"
     },
     "metadata": {},
     "execution_count": 226
    }
   ],
   "source": [
    "# 学習データ\n",
    "performance(perform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.9284436493738819, 0.8693467336683417, 0.8979238754325258)"
     },
     "metadata": {},
     "execution_count": 227
    }
   ],
   "source": [
    "# 評価データ\n",
    "performance(perform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 57. 特徴量の重みの確認\n",
    "\n",
    "52で学習したロジスティック回帰モデルの中で，重みの高い特徴量トップ10と，重みの低い特徴量トップ10を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         Feature  Coefficient\n132        Chris     2.846989\n245   Kardashian     2.635808\n1490        Paul     2.384013\n783       Harris     2.220136\n1390      Cannes     2.217722\n711       George     2.193563\n381         Film     2.061563\n363        Miley     2.049237\n158          Met     2.044361\n775        Movie     2.023829",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Coefficient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>132</th>\n      <td>Chris</td>\n      <td>2.846989</td>\n    </tr>\n    <tr>\n      <th>245</th>\n      <td>Kardashian</td>\n      <td>2.635808</td>\n    </tr>\n    <tr>\n      <th>1490</th>\n      <td>Paul</td>\n      <td>2.384013</td>\n    </tr>\n    <tr>\n      <th>783</th>\n      <td>Harris</td>\n      <td>2.220136</td>\n    </tr>\n    <tr>\n      <th>1390</th>\n      <td>Cannes</td>\n      <td>2.217722</td>\n    </tr>\n    <tr>\n      <th>711</th>\n      <td>George</td>\n      <td>2.193563</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>Film</td>\n      <td>2.061563</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>Miley</td>\n      <td>2.049237</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>Met</td>\n      <td>2.044361</td>\n    </tr>\n    <tr>\n      <th>775</th>\n      <td>Movie</td>\n      <td>2.023829</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 245
    }
   ],
   "source": [
    "model = pd.DataFrame({\"Feature\":x_train.columns.tolist(), \"Coefficient\":lr.coef_.flatten()})\n",
    "model = model.sort_values(\"Coefficient\", ascending=False)\n",
    "model.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        Feature  Coefficient\n606       Apple    -1.977237\n584     Billion    -2.001221\n147        Bank    -2.011097\n93        China    -2.048291\n289       Ebola    -2.069122\n142         CEO    -2.094190\n1218  Obamacare    -2.106589\n682     Climate    -2.223175\n553    Facebook    -2.334967\n409      Google    -3.022455",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Coefficient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>606</th>\n      <td>Apple</td>\n      <td>-1.977237</td>\n    </tr>\n    <tr>\n      <th>584</th>\n      <td>Billion</td>\n      <td>-2.001221</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>Bank</td>\n      <td>-2.011097</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>China</td>\n      <td>-2.048291</td>\n    </tr>\n    <tr>\n      <th>289</th>\n      <td>Ebola</td>\n      <td>-2.069122</td>\n    </tr>\n    <tr>\n      <th>142</th>\n      <td>CEO</td>\n      <td>-2.094190</td>\n    </tr>\n    <tr>\n      <th>1218</th>\n      <td>Obamacare</td>\n      <td>-2.106589</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>Climate</td>\n      <td>-2.223175</td>\n    </tr>\n    <tr>\n      <th>553</th>\n      <td>Facebook</td>\n      <td>-2.334967</td>\n    </tr>\n    <tr>\n      <th>409</th>\n      <td>Google</td>\n      <td>-3.022455</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "source": [
    "model.tail(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 58. 正則化パラメータの変更\n",
    "\n",
    "ロジスティック回帰モデルを学習するとき，正則化パラメータを調整することで，学習時の過学習（overfitting）の度合いを制御できる．異なる正則化パラメータでロジスティック回帰モデルを学習し，学習データ，検証データ，および評価データ上の正解率を求めよ．実験の結果は，正則化パラメータを横軸，正解率を縦軸としたグラフにまとめよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       precision_train  recall_train  F1score_train  precision_test  \\\n0.01          0.850585      0.681490       0.756706        0.849785   \n0.10          0.923877      0.875240       0.898901        0.916974   \n0.50          0.956758      0.930769       0.943585        0.927536   \n1.00          0.964715      0.946394       0.955467        0.928444   \n5.00          0.976074      0.961058       0.968508        0.928826   \n10.00         0.979577      0.968510       0.974012        0.919499   \n\n       recall_test  F1score_test  \n0.01      0.663317      0.745061  \n0.10      0.832496      0.872695  \n0.50      0.857621      0.891210  \n1.00      0.869347      0.897924  \n5.00      0.874372      0.900777  \n10.00     0.860972      0.889273  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision_train</th>\n      <th>recall_train</th>\n      <th>F1score_train</th>\n      <th>precision_test</th>\n      <th>recall_test</th>\n      <th>F1score_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.01</th>\n      <td>0.850585</td>\n      <td>0.681490</td>\n      <td>0.756706</td>\n      <td>0.849785</td>\n      <td>0.663317</td>\n      <td>0.745061</td>\n    </tr>\n    <tr>\n      <th>0.10</th>\n      <td>0.923877</td>\n      <td>0.875240</td>\n      <td>0.898901</td>\n      <td>0.916974</td>\n      <td>0.832496</td>\n      <td>0.872695</td>\n    </tr>\n    <tr>\n      <th>0.50</th>\n      <td>0.956758</td>\n      <td>0.930769</td>\n      <td>0.943585</td>\n      <td>0.927536</td>\n      <td>0.857621</td>\n      <td>0.891210</td>\n    </tr>\n    <tr>\n      <th>1.00</th>\n      <td>0.964715</td>\n      <td>0.946394</td>\n      <td>0.955467</td>\n      <td>0.928444</td>\n      <td>0.869347</td>\n      <td>0.897924</td>\n    </tr>\n    <tr>\n      <th>5.00</th>\n      <td>0.976074</td>\n      <td>0.961058</td>\n      <td>0.968508</td>\n      <td>0.928826</td>\n      <td>0.874372</td>\n      <td>0.900777</td>\n    </tr>\n    <tr>\n      <th>10.00</th>\n      <td>0.979577</td>\n      <td>0.968510</td>\n      <td>0.974012</td>\n      <td>0.919499</td>\n      <td>0.860972</td>\n      <td>0.889273</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 261
    }
   ],
   "source": [
    "figmat = dict()\n",
    "c_s = [0.01, 0.1, 0.5, 1, 5, 10]\n",
    "for c in c_s:\n",
    "    # Model construction\n",
    "    lr = LogisticRegression(C=c, penalty=\"l2\")\n",
    "    lr.fit(x_train, y_train)\n",
    "    # \n",
    "    perform_train = pd.DataFrame({\"Measured\":y_train, \"Predict\":lr.predict(x_train)}).groupby(\"Predict\").Measured.value_counts().unstack(level=1)\n",
    "    perform_test = pd.DataFrame({\"Measured\":y_test, \"Predict\":lr.predict(x_test)}).groupby(\"Predict\").Measured.value_counts().unstack(level=1)\n",
    "    figmat[c] = list(performance(perform_train)) + list(performance(perform_test))\n",
    "    #\n",
    "columns = [\"precision_train\", \"recall_train\", \"F1score_train\", \"precision_test\", \"recall_test\", \"F1score_test\"]\n",
    "figmat = pd.DataFrame(figmat, index=columns).T\n",
    "figmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 59. ハイパーパラメータの探索\n",
    "\n",
    "学習アルゴリズムや学習パラメータを変えながら，カテゴリ分類モデルを学習せよ．検証データ上の正解率が最も高くなる学習アルゴリズム・パラメータを求めよ．また，その学習アルゴリズム・パラメータを用いたときの評価データ上の正解率を求めよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}